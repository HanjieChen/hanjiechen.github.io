<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html>
<head>
	<div class="navbar">
		<a href="./index.html"><font size="+1">Home</font></a>
		<a href="./publication.html"><font size="+1">Publications</font></a>
    <a href="./teach.html"><font size="+1">Teaching</font></a>
    <a href="./awards.html"><font size="+1">Awards</font></a>
		<a href="./misc.html"><font size="+1">Misc</font></a>
	</div>
    <title>Hanjie Chen</title>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
    <link rel="stylesheet" type="text/css" href="style.css"/>
</head>
<body style="color: rgba(0, 0, 0, 0.938);margin:0;padding:0">
<div id="wrapper">
  <div id="content-wrap">
    <div id="content">
      <div id="main">
        <tr>
        <p style="padding-right:30px;"> <img id="headshot" "float-right" align="right" alt="HanjieChen" src="hanjie.jpeg" width="180" height="185"/></p>

            <p><font size="+3"><strong>&nbsp;Hanjie Chen</strong></font></p>
            <p></p>
            <p style="line-height:90%"><font size="3"><a href="https://www.clsp.jhu.edu/" style="color:#9B0145;">&nbsp;&nbsp;Center for Language and Speech Processing</a></font></p>
            <p style="line-height:90%"><font size="3"><a href="https://www.jhu.edu/" style="color:#9B0145;">&nbsp;&nbsp;Johns Hopkins University</a></font></p>
            <p style="line-height:90%"><font size="3"><strong>&nbsp;&nbsp;Address:</strong> Hackerman Hall, 3101 Wyman Park Dr, Baltimore, MD 21218</font></p>
            <p style="line-height:90%"><font size="3"><strong>&nbsp;&nbsp;Email:</strong> hchen210@jh.edu</font></p>
	          <!-- <p style="line-height:90%"><font size="3"><strong>&nbsp;&nbsp;Links:</strong><a href="https://drive.google.com/file/d/1kpwKIMjEHGwSE2xJGnuXwKhxE4Wm31dr/view?usp=sharing" style="color:#9B0145;">&nbsp;&nbsp;<u>CV</u></a></font></strong><a href="https://scholar.google.com/citations?user=CXg6L4wAAAAJ&hl=en" style="color:#9B0145;">&nbsp;&nbsp;<u>Google Scholar</u></a></font> </strong><a href="https://github.com/HanjieChen" style="color:#9B0145;">&nbsp;&nbsp;<u>GitHub</u></a></p> -->
            <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
            &nbsp;&nbsp;&nbsp;&nbsp;<a href="https://drive.google.com/file/d/1kpwKIMjEHGwSE2xJGnuXwKhxE4Wm31dr/view?usp=sharing"><i class="ai ai-cv-square ai-2x" style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <a href="https://scholar.google.com/citations?user=CXg6L4wAAAAJ&hl=en"><i class="ai ai-google-scholar ai-2x" style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
            <a href="https://github.com/HanjieChen"><i class="fa fa-github" style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <a href="https://twitter.com/hanjie_chen?lang=en"><i class="fa fa-twitter" style="font-size:26px; color:#9B0145">&nbsp;</i></a>
        <!-- <p></p> -->

        </tr>
		<hr style="color:rgb(218, 218, 218);">

        <h1><a name="biography">About Me</h1>
        <p>I am a Postdoctoral Fellow in the <a href="https://www.clsp.jhu.edu/" style="color:#9B0145;">Center for Language and Speech Processing @ Johns Hopkins University</a>, working with <a href="https://www.cs.jhu.edu/~mdredze/" style="color:#9B0145;">Prof. Mark Dredze</a>. My research interests lie in Trustworthy AI, Natural Language Processing (NLP), and Interpretable Machine Learning. I aim to develop explainable AI techniques that are easily accessible to
          system developers and end users for building trustworthy and reliable intelligent systems. My current research is centered around <b>trustworthy NLP</b>, with an emphasis on <b>interpretability</b>, <b>robustness</b>, and <b>fairness</b>, to support the understanding and interaction between humans and neural language models. I obtained my Ph.D. in Computer Science in May 2023 at the <a href="https://www.virginia.edu/" style="color:#9B0145;">University of Virginia</a>, where my advisor was <a href="http://yangfengji.net/" target="_blank" style="color:#9B0145;">Prof. Yangfeng Ji</a>.
          <p style="font-size:16px">&#11088; I will join the <a href="https://csweb.rice.edu/" style="color:#01569b;">Department of Computer Science @ Rice University</a> as a tenure-track Assistant Professor starting July 2024. I'm actively looking for motivated students to join my group. Please feel free to reach out (<a style="color:#01569b;">hanjie@rice.edu</a>) if you are interested in collaborating or working with me.</p>
	  <p style="font-size:16px">&#128293; <a style="color:#d93b3b;"><b>Prospective students</b></a>: I am recruiting 1-2 PhD students for Fall 2024. Please apply to our <a href="https://csweb.rice.edu/academics/graduate-programs/graduate-admission" style="color:#01569b;">graduate programs</a>.</p>   
          <dl style="background-color:#b9a2100f">
            <p></p>
            <p style="font-size:18px">&#128204; <a style="color:#6c3a3af2;"><b>Research Overview</b></a></p>
              <p style="padding-left:0px;"> <img align="left" src="overview.png" width="300" style="border: 0;" />
                <ul style="overflow: hidden; padding-right:10px;">
                <li> <b>How to understand black-box models?</b>
                  <br><a><font size="2">I develop explanation methods to explain model
                     <b>predictions</b> (<a href="http://aclanthology.lst.uni-saarland.de/2020.acl-main.494.pdf" style="color:#b04605;">ACL'2020</a>, 
                     <a href="https://aclanthology.org/2021.naacl-main.306.pdf" style="color:#b04605;">NAACL'2021</a>) 
                     and <b>uncertainty</b> (<a href="https://arxiv.org/pdf/2201.03742.pdf" style="color:#b04605;">AAAI-UDM'2023</a>) 
                     and evaluate explanations to understand model <b>reasoning</b> (<a href="https://arxiv.org/pdf/2210.04982.pdf" style="color:#b04605;">ACL'2023</a>)
                     and <b>robustness</b> (<a href="https://arxiv.org/pdf/2212.05327.pdf" style="color:#b04605;">BlackboxNLP'2022</a>, 
                     <a href="https://arxiv.org/pdf/2108.04990.pdf" style="color:#b04605;">2021</a>) </font></a>
                <li> <b>How to build trustworthy models?</b>
                  <br><a><font size="2">To cultivate trustworthiness in <b>existing</b> models, I have designed 
                    <b>data augmentation</b> (<a href="https://arxiv.org/pdf/1909.04225.pdf" style="color:#b04605;">NeurIPS WS'2019</a>), 
                    <b>variational word masks</b> (<a href="https://aclanthology.org/2020.emnlp-main.347v2.pdf" style="color:#b04605;">EMNLP'2020</a>), 
                    and <b>interaction graphs</b> (<a style="color:#b04605;">AAAI'2023</a>), 
                    to make model decision-making transparent and reliable </font></a>
                <li> <b>How to improve models via explanations?</b>
                  <br><a><font size="2">I diagnose and debug models, especially their <b>robustness</b> and <b>fairness</b>, 
                    through the lens of explanations and develop solutions to improve them (<a href="https://arxiv.org/pdf/2203.12709.pdf" style="color:#b04605;">AAAI'2022</a>,
                    <a href="https://arxiv.org/pdf/2204.08039.pdf" style="color:#b04605;">ACL WS'2022</a>)
                     </font></a>
              </ul>
              </p>
          </dl>
        
          <dl style="background-color:#b953100c">
            <p></p>
            <p style="font-size:18px"> <a style="color:#6c3a3af2;"><b>Highlights</b></a></p>
            <p style="font-size:16px">&#127891; Received the Outstanding Doctoral Student Award, UVA, 2023</p>
            <p style="font-size:16px">&#127881; Received the John A. Stankovic Graduate Research Award, UVA, 2023</p>
            <p style="font-size:16px">&#127881; I was awarded the Carlos and Esther Farrar Fellowship, 2022 - 2023</p>
            <p style="font-size:16px">&#128105;&#8205;&#127979; As the primary instructor, I co-designed and taught the course, <a href="https://uvanlp.org/iml-2022/" target="_blank" style="color:#9B0145;">CS 6501/4501 Interpretable Machine Learning</a>, at UVA in Spring 2022, and was awarded the UVA CS Outstanding Graduate Teaching Award and University-wide Graduate Teaching Awards Nominee (<b>top 5%</b> of graduate instructors)</p>
            <p style="font-size:16px">&#128221; My collaborators and I are actively updating a <a href="https://github.com/HanjieChen/Reading-List/wiki" style="color:#9B0145;">Reading List</a> with interesting papers</p>
            <p></p>
          </dl>


        <p></p>
        <h1><a name="activities">Research Experience</h1>
          <!-- <b><font size="+1">&nbspService</b> -->
          <ul>
              <li> <b>Allen Institute for AI (AI2)</b>, Seattle, WA, May 2022 - Oct. 2022
                <p><i>Mosaic Group</i></p>
                <ul>
                <li> Research Intern
                <li> Manager: <a href="https://homes.cs.washington.edu/~yejin/" target="_blank" style="color:#9B0145;">Yejin Choi</a>
                <li> Mentors: <a href="https://swabhs.com/" target="_blank" style="color:#9B0145;">Swabha Swayamdipta</a>, <a href="https://users.soe.ucsc.edu/~hannahbrahman/" target="_blank" style="color:#9B0145;">Faeze Brahman</a>, <a href="https://shanzhenren.github.io/" target="_blank" style="color:#9B0145;">Xiang Ren</a>
                </ul>
              <li> <b>Microsoft Research</b>, Redmond, WA, May 2021 - Aug. 2021
                <p><i>Language and Information Technologies Group</i></p>
                <ul>
                <li> Research Intern
                <li> Manager: <a href="https://www.microsoft.com/en-us/research/people/hassanam/" target="_blank" style="color:#9B0145;">Ahmed H. Awadallah</a>
                <li> Mentors: <a href="https://www.microsoft.com/en-us/research/people/zheng/" target="_blank" style="color:#9B0145;">Guoqing Zheng</a>, <a href="https://www.linkedin.com/in/srinagesh-sharma-313536156/" target="_blank" style="color:#9B0145;">Srinagesh Sharma</a>
                </ul>
              <li> <b>IBM Research</b>, New York, NY, Jun. 2020 - Aug. 2020
                <p><i>Thomas J. Watson Research Center</i></p>
                <ul>
                <li> Research Intern
                <li> Manager: <a href="https://www.linkedin.com/in/luis-lastras-9a862a14/" target="_blank" style="color:#9B0145;">Luis Lastras</a>
                <li> Mentors: <a href="https://researcher.watson.ibm.com/researcher/view.php?person=ibm-chulaka.gunasekara" target="_blank" style="color:#9B0145;">Chulaka Gunasekara</a>, <a href="https://songfeng.github.io/" target="_blank" style="color:#9B0145;">Song Feng</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-hwan" target="_blank" style="color:#9B0145;">Hui Wan</a>, <a href="https://jatinganhotra.com/" target="_blank" style="color:#9B0145;">Jatin Ganhotra</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=in-jsachind" target="_blank" style="color:#9B0145;">Sachindra Joshi</a>
                </ul>

          </ul>
        <h1><a name="activities">Academic Activities</h1>
          <!-- <b><font size="+1">&nbspTalks</b> -->
          <ul>
            <li> Presentation on <i>REV: Information-Theoretic Evaluation of Free-Text Rationales</i> <a href="https://2023.aclweb.org/" style="color:#9B0145;">@ ACL 2023</a>, July 2023
            <li> Invited Talk on <i>Bridging the Trustworthy Gap between AI and Humans: Interpretation Techniques for Modern NLP</i> at the <a href="https://www.clsp.jhu.edu/events/hanjie-chen-university-of-virginia/?instance_id=3253#.ZFFSr-zMJz8" style="color:#9B0145;">CLSP Seminar @ Johns Hopkins University</a>, Mar. 2023
            <li> Presentation on <i>Information-Theoretic Evaluation of Free-Text Rationales with Conditional V-Information</i> at <a href="https://tsrml2022.github.io/" style="color:#9B0145;">Trustworthy and Socially Responsible Machine Learning (TSRML) Workshop @ NeurIPS</a>, Dec. 2022
            <li> Presentation on <i>Explaining Predictive Uncertainty by Looking Back at Model Explanations</i> at <a href="https://wimlworkshop.org/" style="color:#9B0145;">WiML Workshop 2022 @ NeurIPS</a>, Nov. 2022
            <li> Talk on <i>REV: Information-Theoretic Evaluation of Free-Text Rationales</i> <a href="https://allenai.org/" style="color:#9B0145;">@ Allen Institute for AI (AI2)</a>, Oct. 2022
            <li> Paper presentation on <i>Pathologies of Pre-trained Language Models in Few-shot Fine-tuning</i> <a href="https://insights-workshop.github.io/index" style="color:#9B0145;">Insights Workshop @ ACL 2022</a>, May 2022
            <li> Paper presentation on <i>Adversarial Training for Improving Model Robustness? Look at Both Prediction and Interpretation</i> <a href="https://aaai.org/Conferences/AAAI-22/" style="color:#9B0145;">@ AAAI 2022</a>, Feb. 2022
            <li> Invited talk on <i>Improving Model Robustness via Interpretation-based Adversarial Training</i> <a href="https://mp.weixin.qq.com/s/pc79dVgaaoBcBrKwmObLEQ" style="color:#9B0145;">@ MLNLP</a>, Dec. 2021
            <li> Presentation on <i>Adversarial Training for Improving Model Robustness? Look at Both Prediction and Interpretation</i> at <a href="https://wimlworkshop.org/" style="color:#9B0145;">WiML Workshop 2021 @ NeurIPS</a>, Dec. 2021
            <li> Presentation on <i>Adversarial Training for Improving Model Robustness? Look at Both Prediction and Interpretation</i> <a href="https://engineering.virginia.edu/events/2021-fall-cs-research-symposium" style="color:#9B0145;">@ 2021 Fall UVA CS Research Symposium</a>, Dec. 2021
            <li> Paper presentation on <i>Explaining Neural Network Predictions on Sentence Pairs via Learning Word-Group Masks</i> <a href="https://2021.naacl.org/" style="color:#9B0145;">@ NAACL 2021</a>, Jun. 2021
            <li> 2021 CRA-WP Grad Cohort for Women Workshop, Apr. 2021
            <li> Poster presentation <a href="https://capwic.org/#:~:text=CAPWIC%20is%20the%20ACM%20Capital,supporters%20of%20women%20in%20computing." style="color:#9B0145;">@ ACM Capital Region Celebration of Women in Computing (CAPWIC)</a>, Mar. 2021
            <li> Paper presentation on <i>Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers</i> <a href="https://2020.emnlp.org/" style="color:#9B0145;">@ EMNLP 2020</a>, Nov. 2020
            <li> Presentation on <i>Learning Variational Masks for Explainable Next Utterance Prediction in Dialog Systems</i> at IBM Research, Aug. 2020
            <li> Paper presentation on <i>Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection</i> <a href="https://acl2020.org/" style="color:#9B0145;">@ ACL 2020</a>, Jul. 2020
            <li> Poster presentation on <i>Improving the Explainability of Neural Sentiment Classifiers via Data Augmentation</i> <a href="https://sites.google.com/view/robust-ai-in-fs-2019/home" style="color:#9B0145;">@ NeurIPS 2019 Workshop on Robust AI in Financial Services</a>, Dec. 2019
            <li> Poster presentation on <i>Building Hierarchical Interpretations in Natural Language via Feature Interaction Detection</i> <a href="https://engineering.virginia.edu/cs-research-symposium-fall-2019" style="color:#9B0145;">@ UVA CS Research Symposium Fall 2019</a>, Oct. 2019
            <li> Invited talk on <i>How to Train a More Interpretable Neural Text Classifier</i>, <a href="https://uvaml.github.io/" style="color:#9B0145;">AIML-Seminar @ UVA</a>, Apr. 2019
            <li> Poster presentation on <i>An Empirical Comparison on Convolutional and Recurrent Neural Networks for NLP</i> at the JUMP Undergraduate Research Initiative, UVA, Nov. 2018
          </ul>
        <h1><a name="activities">Professional Service</h1>
          <!-- <b><font size="+1">&nbspService</b> -->
          <ul>
              <li> <b>Diversity Representative</b> for UVA Computer Science Graduate Student Group (CSGSG) Council, 2022
              <li> <b>Area Chair</b> for WiML Workshop @ NeurIPS 2022
              <li> <b>Program Committee</b>: ACL 2023, AAAI 2023, EMNLP 2021 - 2023, NAACL 2021, EACL 2023, CoNLL 2021 - 2022, NLPCC 2022, ACL DialDoc Workshop 2022, EMNLP BlackboxNLP Workshop 2021, 2023, NeurIPS Explainable AI Approaches for Debugging and Diagnosis Workshop 2021, Document-grounded Dialogue Workshop 2021, MASC-SLL 2020
              <li> <b>Reviewer</b>: NeurIPS 2023, EMNLP 2023, ACL Rolling Review 2021 - 2022, ACL 2020 - 2021, EMNLP BlackboxNLP Workshop 2022, CoNLL 2019 - 2020, NLPCC 2019 - 2021
          </ul>

		<hr style="color:rgb(218, 218, 218);">
		<div style="text-align: center; font-size: 18px;"><small>Last update: 08/2023</small>
		</div>
		<br>
      </div>
    </div>
  </div>
</div>

</body>
</html>
